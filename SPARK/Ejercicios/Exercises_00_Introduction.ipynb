{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "73nutI1L6Rwy"
      },
      "source": [
        "# Introduction\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jq9d0x1OTh2N"
      },
      "source": [
        "## Prerrequisites"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2_DQBVj_KNvL"
      },
      "source": [
        "Installing Spark and Java in VM\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "xEbGSM3_NM-z"
      },
      "outputs": [],
      "source": [
        "# install Java8\n",
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
        "# download spark3.0.1\n",
        "!wget -q https://apache.osuosl.org/spark/spark-3.3.1/spark-3.3.1-bin-hadoop2.tgz"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iwL-9uf-47Mi",
        "outputId": "12b5b4f5-3993-4a22-b16f-39c63cb466bf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total 267680\n",
            "drwxr-xr-x 1 root root      4096 Dec  7 14:41 \u001b[0m\u001b[01;34msample_data\u001b[0m/\n",
            "-rw-r--r-- 1 root root 274099817 Oct 15 10:53 spark-3.3.1-bin-hadoop2.tgz\n"
          ]
        }
      ],
      "source": [
        "ls -l # check the .tgz is there"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "5EjWtRuY47Ky"
      },
      "outputs": [],
      "source": [
        "# unzip it\n",
        "!tar xf spark-3.3.1-bin-hadoop2.tgz"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "FwpS7Yfd47Ii"
      },
      "outputs": [],
      "source": [
        "!pip install -q findspark"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_vqB07r35KjL"
      },
      "source": [
        "Define the environment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "8bgLASos5OJi"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = \"/content/spark-3.3.1-bin-hadoop2\"\n",
        "os.environ[\"PYSPARK_SUBMIT_ARGS\"] = \"--master local[*] pyspark-shell\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rdFv-xxITa2J"
      },
      "source": [
        "Start Spark Session\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "BDLMbVBATf9K",
        "outputId": "3a9d3714-3023-4123-8810-1c9df3281599"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'3.3.1'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "import findspark\n",
        "findspark.init(\"spark-3.3.1-bin-hadoop2\")# SPARK_HOME\n",
        "\n",
        "from pyspark.sql import SparkSession\n",
        "\n",
        "# create the session\n",
        "spark = SparkSession \\\n",
        "        .builder \\\n",
        "        .appName(\"Introduction\") \\\n",
        "        .master(\"local[*]\") \\\n",
        "        .getOrCreate()\n",
        "\n",
        "spark.version"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 219
        },
        "id": "G28MgeRJHKJ5",
        "outputId": "823b8039-1541-484b-8d6d-b96cb053f5d9"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<pyspark.sql.session.SparkSession at 0x7f4f0c1d9f70>"
            ],
            "text/html": [
              "\n",
              "            <div>\n",
              "                <p><b>SparkSession - in-memory</b></p>\n",
              "                \n",
              "        <div>\n",
              "            <p><b>SparkContext</b></p>\n",
              "\n",
              "            <p><a href=\"http://19b33ea23a56:4040\">Spark UI</a></p>\n",
              "\n",
              "            <dl>\n",
              "              <dt>Version</dt>\n",
              "                <dd><code>v3.3.1</code></dd>\n",
              "              <dt>Master</dt>\n",
              "                <dd><code>local[*]</code></dd>\n",
              "              <dt>AppName</dt>\n",
              "                <dd><code>Introduction</code></dd>\n",
              "            </dl>\n",
              "        </div>\n",
              "        \n",
              "            </div>\n",
              "        "
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "spark"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "qPrOO29YRuDB"
      },
      "outputs": [],
      "source": [
        "# For Pandas conversion optimization\n",
        "spark.conf.set(\"spark.sql.execution.arrow.enabled\", \"true\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Z0h3dF9Vg4X"
      },
      "source": [
        "Download datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KBDin-0sXgyI",
        "outputId": "59bebc99-c7d0-449d-a55a-814e8b49dcea"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "characters.csv\tel_quijote.txt\tfrankenstein.txt  planets.csv\n"
          ]
        }
      ],
      "source": [
        "!mkdir -p /dataset\n",
        "!wget -q https://github.com/masfworld/datahack_docker/raw/master/zeppelin/data/frankenstein.txt -P /dataset\n",
        "!wget -q https://github.com/masfworld/datahack_docker/raw/master/zeppelin/data/el_quijote.txt -P /dataset\n",
        "!wget -q https://github.com/masfworld/datahack_docker/raw/master/zeppelin/data/characters.csv -P /dataset\n",
        "!wget -q https://github.com/masfworld/datahack_docker/raw/master/zeppelin/data/planets.csv -P /dataset\n",
        "!ls /dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "02Zwm3NRXS_I"
      },
      "source": [
        "## RDDs\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h1o6f6QOjTcZ"
      },
      "source": [
        "Example 1"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Leer un fichero con spark. 'textFile' ya es un RDD"
      ],
      "metadata": {
        "id": "-wWvPfq4Y12C"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "HnbafeFCVk8d",
        "outputId": "f6b20149-36b4-4daf-d1bb-60cd8ac88ee4"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'FRANKENSTEIN'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "textFile1 = spark.sparkContext.textFile(\"../dataset/frankenstein.txt\")\n",
        "textFile1.first()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Función para contar cuantas filas hay"
      ],
      "metadata": {
        "id": "UrRzQ5EIZnUU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "textFile1.count()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ux1XEsJnZi_Q",
        "outputId": "29fc2f94-9207-4638-d8c8-55f831eed341"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "7237"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9a00GmwOZmM2"
      },
      "source": [
        "Creating parallelized collections\n",
        "A very quick way to create RDD from the shell, when we are learning, is to create a parallelized collection. To do this:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yzU_4EjAjZgh"
      },
      "source": [
        "Example 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SgireGq6YWEj",
        "outputId": "182623be-e7a2-419c-9230-6d783eedbf37"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "75"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "distData = spark.sparkContext.parallelize([25, 20, 15, 10, 5])\n",
        "distData.reduce(lambda x ,y: x + y)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R5hVQSRDaNAZ"
      },
      "source": [
        "What type of variabe is distData?\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XoIVol1e4tsu",
        "outputId": "8605927e-a2a6-4227-e24b-82d4ad7024db"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "pyspark.rdd.RDD"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "type(distData)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bX0FXU7JawRm"
      },
      "source": [
        "Exercise 1. Count the number of line on \"el_quijote.txt\" file\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "q2Xr7Z9u_dBT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "36ca781b-a802-41b4-817d-f555a4d11690"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2186"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "textFile2 = spark.sparkContext.textFile(\"../dataset/el_quijote.txt\")\n",
        "textFile2.count()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "prvVhMD4a5o7"
      },
      "source": [
        "Exercise 2. Print the first line of \"el_quijote.txt\" file\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "textFile2.first()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "0Lnoewgfa49w",
        "outputId": "e85f3ff3-42bf-4ea4-d624-167d03e93399"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'DON QUIJOTE DE LA MANCHA'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wAxxBSrBb92y"
      },
      "source": [
        "## Tranformations and Actions over RDDs "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4fc-rQBNjnNi"
      },
      "source": [
        "Example 3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qvxep4yubxtC",
        "outputId": "6404297e-b012-45bc-8ff4-7d95cb681146"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "7237"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "textFile1.count() # Number of elements in the RDD "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "irxzzmfwjyYi"
      },
      "source": [
        "Example 4"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Leemos cuantas veces aparece cada linea.\n",
        "recueByKey --> para las lineas que sean iguales hará la función a + b. \n",
        "\n",
        "Lo que estamos haciendo es contar el número de lineas diferentes."
      ],
      "metadata": {
        "id": "2w8j9P6ldLRY"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MpkUk7t9cfoL",
        "outputId": "4cbe32ad-9e4d-4377-d632-d430fccd8e96"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "6423"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "source": [
        "# ReduceByKey\n",
        "# Lines (distinc) count\n",
        "lines = spark.sparkContext.textFile(\"../dataset/frankenstein.txt\")\n",
        "pairs = lines.map(lambda s: (s, 1))\n",
        "counts = pairs.reduceByKey(lambda a, b: a + b).cache()\n",
        "counts.count()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0WdkFrcC4tsw",
        "outputId": "913e89b0-bfc9-4dfb-97ba-f74b149add8d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[('FRANKENSTEIN', 1),\n",
              " ('', 811),\n",
              " ('Letter 1', 1),\n",
              " ('commencement of an enterprise which you have regarded with such evil', 1),\n",
              " ('forebodings.  I arrived here yesterday, and my first task is to assure', 1)]"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "counts.collect()[0:5] #[0:5] to limit the output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eA1qDkPT4tsw",
        "outputId": "953444fd-cfe5-4ebe-bff5-10e066e4f999"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('', 811),\n",
              " ('To Mrs. Saville, England', 3),\n",
              " ('Your affectionate brother,', 2),\n",
              " ('me.', 2),\n",
              " ('FRANKENSTEIN', 1),\n",
              " ('Letter 1', 1),\n",
              " ('commencement of an enterprise which you have regarded with such evil', 1),\n",
              " ('forebodings.  I arrived here yesterday, and my first task is to assure', 1),\n",
              " ('my dear sister of my welfare and increasing confidence in the success', 1),\n",
              " ('of my undertaking.', 1)]"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ],
      "source": [
        "# SortBy (frequency in this case)\n",
        "sortedByFreq = counts.sortBy(lambda x: x[1], False)\n",
        "sortedByFreq.collect()[0:10]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a6c2qVSLj4Cy"
      },
      "source": [
        "Example 5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fDwoLMbbdGPN",
        "outputId": "ec900935-c6e1-455a-f46b-769f827a6da8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3712"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ],
      "source": [
        "# Filter\n",
        "\n",
        "linesWithThe = textFile1.filter(lambda line: \"the\" in line)\n",
        "linesWithThe.count()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G18U5fyP4tsx",
        "outputId": "b4efd508-84ea-4f7a-c4e8-205312a9ba6c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Or, The Modern Prometheus',\n",
              " 'You will rejoice to hear that no disaster has accompanied the',\n",
              " 'my dear sister of my welfare and increasing confidence in the success',\n",
              " 'I am already far north of London, and as I walk in the streets of',\n",
              " 'Petersburgh, I feel a cold northern breeze play upon my cheeks, which',\n",
              " 'feeling?  This breeze, which has travelled from the regions towards',\n",
              " 'and vivid.  I try in vain to be persuaded that the pole is the seat of',\n",
              " 'frost and desolation; it ever presents itself to my imagination as the',\n",
              " 'region of beauty and delight.  There, Margaret, the sun is forever',\n",
              " 'visible, its broad disk just skirting the horizon and diffusing a']"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ],
      "source": [
        "linesWithThe.collect()[0:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l7t7_E2M4tsx",
        "outputId": "c2ba4544-7e0a-43f7-cfab-58494a5ef659"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "17"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ],
      "source": [
        "linesWithSuccess = textFile1.filter(lambda line: \"success\" in line)\n",
        "linesWithSuccess.count()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gkDRoRsm4tsx",
        "outputId": "a93cf7a2-21a6-4ffb-c1e0-9725efb30bf1"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['my dear sister of my welfare and increasing confidence in the success',\n",
              " 'success, there will be none to participate my joy; if I am assailed by',\n",
              " 'expect such success, yet I cannot bear to look on the reverse of the',\n",
              " 'But success SHALL crown my endeavours.  Wherefore not?  Thus far I have',\n",
              " 'success and into every minute detail of the measures I had taken to',\n",
              " 'unexplored ocean of truth.  Those of his successors in each branch of',\n",
              " 'unsuccessful, I attributed the failure rather to my own inexperience',\n",
              " 'application equals your ability, I have no doubt of your success.',\n",
              " 'imagination was too much exalted by my first success to permit me to',\n",
              " 'attempts would at least lay the foundations of future success.  Nor']"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ],
      "source": [
        "linesWithSuccess.collect()[0:10]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ngS6b5jUfYen"
      },
      "source": [
        "Exercise 3. Get the frequency with which each word appears in the file \"frankenstein.txt\""
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Utilizamos flatmap porque la salida es 0 más elementos del RDD original. Map solo lo utilizamos si esperamso el mismo número de salida del original."
      ],
      "metadata": {
        "id": "2Gy8xHEmgWjo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Solución del profesor"
      ],
      "metadata": {
        "id": "JKwFZGa2js04"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "words = spark.sparkContext.textFile(\"../dataset/frankenstein.txt\")\n",
        "\n",
        "words.flatMap(lambda x: x.split(\" \")) \\\n",
        ".map(lambda s: (s,1)) \\\n",
        ".reduceByKey(lambda a, b: a+b) \\\n",
        ".map(lambda x: (x[1], x[0])) \\\n",
        ".sortByKey(False) \\\n",
        ".collect()[0:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VaSEY081h37a",
        "outputId": "66b84778-1e0b-4d44-96bb-a83b0da0f435"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(3897, 'the'),\n",
              " (3488, ''),\n",
              " (2904, 'and'),\n",
              " (2720, 'I'),\n",
              " (2634, 'of'),\n",
              " (2072, 'to'),\n",
              " (1629, 'my'),\n",
              " (1338, 'a'),\n",
              " (1072, 'in'),\n",
              " (992, 'was')]"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Solución de internet"
      ],
      "metadata": {
        "id": "3Kj7pLV4jvKW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "word = lines.flatMap(lambda linea: linea.split(\" \")).countByValue()\n",
        "print(f'El número de palabras no repetidas es: {len(word.items())}')\n",
        "for palabra, contador in word.items():\n",
        "  if palabra == 'the':\n",
        "    print(\"{} : {}\".format(palabra, contador))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kNXr_PCUeecd",
        "outputId": "81ee6c15-71bd-4383-ddac-9cb33f93345d"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "El número de palabras no repetidas es: 11606\n",
            "the : 3897\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "034ZWkexhXQF"
      },
      "source": [
        "Exercise 4. get the top 10 words with more than 4 characters\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Lo0dq-QrU0MU"
      },
      "outputs": [],
      "source": [
        "# It is hard, it isn't? So, let's use DF instead :)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Mi solución con diccionarios\n",
        "\n",
        "En mi solución he sacado solo las 10 palabras que más aparecen, la condición de que tenga más de 4 letras no la he contemplado"
      ],
      "metadata": {
        "id": "RMfUNSUUnHN9"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "id": "te778plf-tOy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eda050a0-4119-4acf-e84c-58a5bcfaf7aa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dictionary limited by K is : {'the': 3897, '': 3488, 'and': 2904, 'I': 2720, 'of': 2634, 'to': 2072, 'my': 1629, 'a': 1338, 'in': 1072, 'was': 992}\n"
          ]
        }
      ],
      "source": [
        "#Ordenamos el diccionario por sus valores\n",
        "sorted_words = dict(sorted(word.items(), key=lambda item:item[1], reverse=True))\n",
        "K = 10\n",
        "#Seleccionamos los 10 primero que serán los de mayor número de veces repetidas\n",
        "res = dict(list(sorted_words.items())[0: K]) \n",
        "#Imprimimos el top 10\n",
        "print(\"The top 10 words with more than 4 characters: \" + str(res)) "
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Solución del profesor"
      ],
      "metadata": {
        "id": "t3zX4sgNnKdv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "words.flatMap(lambda x: x.split(\" \")) \\\n",
        ".filter(lambda word: len(word) > 4) \\\n",
        ".map(lambda s: (s,1)) \\\n",
        ".reduceByKey(lambda a, b: a+b) \\\n",
        ".map(lambda x: (x[1], x[0])) \\\n",
        ".sortByKey(False) \\\n",
        ".take(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vSavyzYinMx-",
        "outputId": "e55e6c76-ed62-42e4-cc62-52049c1e8c6f"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(540, 'which'),\n",
              " (187, 'could'),\n",
              " (177, 'would'),\n",
              " (174, 'their'),\n",
              " (152, 'should'),\n",
              " (130, 'these'),\n",
              " (122, 'before'),\n",
              " (107, 'might'),\n",
              " (105, 'myself'),\n",
              " (103, 'every')]"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.7"
    },
    "vscode": {
      "interpreter": {
        "hash": "116b16ce4771ffbe70767d6473d2ec71e30cb9f23544c16e382302f0f8a58d51"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}